{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root=\"./data\",train=True,download=True,transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                              transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
    "                                                          ]))\n",
    "mnist_testset = torchvision.datasets.MNIST(root=\"./data\",train=False,download=True,transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                              transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
    "                                                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of image, always 0, Image\n",
    "mnist_trainset[50000][0][0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,encoder_net):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.encoder = encoder_net\n",
    "\n",
    "    def encode(self,x):\n",
    "        h_e = self.encoder(x)\n",
    "        mu_e, log_var_e = torch.chunk(h_e,chunks=2)\n",
    "        return mu_e, log_var_e\n",
    "\n",
    "    def reparameterization(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu+std*eps\n",
    "    \n",
    "    def sample(self, mu_e, log_var_e):\n",
    "        z = self.reparameterization(mu_e,log_var_e)\n",
    "        return z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,decoder_net):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.num_vals = 10\n",
    "        self.decoder = decoder_net\n",
    "    \n",
    "    def decode(self,z):\n",
    "        h_d = self.decoder(z)\n",
    "        h_d = h_d.view(28,28,10)\n",
    "        #h_d = h_d.view(h_d.shape[0],h_d.shape[1]//self.num_vals,self.num_vals)\n",
    "        print(h_d)\n",
    "        mu_d = torch.softmax(h_d,dim=2)\n",
    "        return mu_d\n",
    "\n",
    "    def sample(self,z):\n",
    "        mu_d = self.decode(z)\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior(nn.Module):\n",
    "    def __init__(self,L):\n",
    "        super(Prior, self).__init__()\n",
    "        self.L = L\n",
    "    \n",
    "    def sample(self, batchsize=1):\n",
    "        z = torch.randn((batchsize,self.L))\n",
    "        return z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,encoder_net,decoder_net):\n",
    "        super(VAE,self)\n",
    "        self.encoder = Encoder(encoder_net)\n",
    "        self.decoder = Decoder(decoder_net)\n",
    "        self.Prior = Prior()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_e,log_var_e = self.encoder.encode(x)\n",
    "        z = self.encoder.sample(mu_e,log_var_e)\n",
    "\n",
    "    def sample(self, batchsize = 1):\n",
    "        z = self.Prior.sample(batchsize)\n",
    "        return self.decoder.sample(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 28**2\n",
    "L = 10\n",
    "num_values = 10\n",
    "encoder = nn.Sequential(nn.Linear(D,2*L))\n",
    "decoder = nn.Sequential(nn.Linear(L,num_values*D))\n",
    "prior = Prior(L)\n",
    "enc = Encoder(encoder)\n",
    "dec = Decoder(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1334,  2.3207,  2.3796,  ..., -0.8393, -1.5502, -1.9580],\n",
      "         [ 0.3444,  0.5484, -0.0282,  ..., -1.0623, -0.0676,  1.0569],\n",
      "         [ 0.3858, -1.0046, -0.0151,  ..., -0.3151, -0.2835,  0.1694],\n",
      "         ...,\n",
      "         [-0.4716, -0.4144, -0.6936,  ..., -0.4585, -0.1470,  1.4116],\n",
      "         [-2.2032, -1.0438,  1.3237,  ...,  0.4377, -0.2266,  1.4836],\n",
      "         [ 1.2631, -0.7472,  0.8377,  ...,  0.0689, -0.9747, -1.3372]],\n",
      "\n",
      "        [[-0.7560, -1.4160,  1.9319,  ...,  0.2219, -2.1717, -0.6164],\n",
      "         [-1.3742, -0.5852, -0.2784,  ..., -0.9649,  1.4528,  0.4080],\n",
      "         [-0.7109,  2.0445,  0.7940,  ...,  0.0040, -0.9433, -1.3810],\n",
      "         ...,\n",
      "         [-0.0633, -0.3249, -1.1690,  ...,  2.1233, -1.4329, -1.8994],\n",
      "         [ 2.1626,  1.4148,  0.0403,  ...,  0.7065,  0.6346, -0.1113],\n",
      "         [-0.7569,  0.3757,  0.2186,  ...,  0.6510,  0.2630, -1.3657]],\n",
      "\n",
      "        [[-0.7712,  0.2651,  0.7440,  ..., -1.9657, -1.3228,  2.0920],\n",
      "         [-0.3894, -0.9201, -1.2061,  ..., -0.3520,  0.4530, -0.8113],\n",
      "         [ 0.6721, -0.1627, -1.1664,  ..., -0.6279,  1.1962, -0.1596],\n",
      "         ...,\n",
      "         [ 0.3112, -1.3339, -0.0661,  ..., -0.9454,  0.8349, -1.8963],\n",
      "         [ 2.6674, -0.8443,  1.9643,  ...,  0.2686,  1.3505,  2.9644],\n",
      "         [-0.1844,  1.3878,  1.6053,  ..., -0.3141, -1.0588, -0.4162]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8887, -0.3781, -1.0451,  ...,  0.6595,  1.9813,  2.2316],\n",
      "         [-0.2819,  0.7453, -1.1643,  ..., -0.7216,  0.7087,  0.3389],\n",
      "         [-0.6757,  1.8970,  1.1826,  ..., -0.5475, -0.9520, -0.5500],\n",
      "         ...,\n",
      "         [-1.5958, -0.2785, -0.1940,  ..., -0.9371,  0.4456, -1.2140],\n",
      "         [ 0.6301, -0.5290, -0.4682,  ...,  1.5004,  0.0201,  0.4985],\n",
      "         [-1.6330,  0.5818, -0.5452,  ...,  1.9061,  0.6807, -0.5616]],\n",
      "\n",
      "        [[ 0.9720,  1.2580,  0.8089,  ..., -0.7205, -0.0426,  1.4066],\n",
      "         [-1.9208,  0.4920, -0.1197,  ...,  0.7504,  0.5546,  0.6853],\n",
      "         [-1.0223, -0.1830,  0.1808,  ..., -1.0583, -1.8641,  0.1574],\n",
      "         ...,\n",
      "         [ 0.3496,  0.4096,  0.6659,  ..., -0.9223, -1.8805,  0.9403],\n",
      "         [-0.3945,  0.3629,  2.2619,  ..., -0.0561, -1.2567, -1.9367],\n",
      "         [ 0.6204,  0.2347,  1.7104,  ...,  1.2099, -0.1211, -0.1712]],\n",
      "\n",
      "        [[ 1.0594, -0.0824,  2.0526,  ..., -0.2551,  0.3827,  0.0403],\n",
      "         [-0.2058,  1.4960,  0.3170,  ...,  0.1487, -0.5464, -0.4473],\n",
      "         [-1.4519,  1.7682, -0.7014,  ...,  1.2063,  0.9967, -0.2785],\n",
      "         ...,\n",
      "         [ 0.8769,  1.8118, -1.1143,  ...,  1.7432,  2.2691, -0.1369],\n",
      "         [-0.1800, -1.2124, -1.1255,  ..., -0.2972,  0.3065, -0.1104],\n",
      "         [ 0.7487, -0.1451,  0.4104,  ...,  1.5745, -0.4355,  1.8704]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mu, log = enc.encode(torch.flatten(mnist_trainset[0][0][0]))\n",
    "z = enc.sample(mu,log)\n",
    "o = dec.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.0667, 0.2186, 0.2318,  ..., 0.0093, 0.0046, 0.0030],\n",
       "          [0.0382, 0.0469, 0.0263,  ..., 0.0094, 0.0253, 0.0780],\n",
       "          [0.1126, 0.0280, 0.0754,  ..., 0.0559, 0.0577, 0.0907],\n",
       "          ...,\n",
       "          [0.0482, 0.0511, 0.0386,  ..., 0.0489, 0.0667, 0.3171],\n",
       "          [0.0070, 0.0223, 0.2376,  ..., 0.0980, 0.0504, 0.2788],\n",
       "          [0.2858, 0.0383, 0.1868,  ..., 0.0866, 0.0305, 0.0212]],\n",
       " \n",
       "         [[0.0415, 0.0214, 0.6098,  ..., 0.1103, 0.0101, 0.0477],\n",
       "          [0.0068, 0.0149, 0.0202,  ..., 0.0102, 0.1142, 0.0402],\n",
       "          [0.0277, 0.4364, 0.1250,  ..., 0.0567, 0.0220, 0.0142],\n",
       "          ...,\n",
       "          [0.0639, 0.0492, 0.0211,  ..., 0.5688, 0.0162, 0.0102],\n",
       "          [0.3459, 0.1638, 0.0414,  ..., 0.0806, 0.0750, 0.0356],\n",
       "          [0.0387, 0.1200, 0.1026,  ..., 0.1581, 0.1072, 0.0210]],\n",
       " \n",
       "         [[0.0276, 0.0779, 0.1258,  ..., 0.0084, 0.0159, 0.4841],\n",
       "          [0.0673, 0.0396, 0.0297,  ..., 0.0699, 0.1563, 0.0441],\n",
       "          [0.1006, 0.0437, 0.0160,  ..., 0.0274, 0.1700, 0.0438],\n",
       "          ...,\n",
       "          [0.0698, 0.0135, 0.0478,  ..., 0.0199, 0.1178, 0.0077],\n",
       "          [0.2710, 0.0081, 0.1342,  ..., 0.0246, 0.0726, 0.3647],\n",
       "          [0.0482, 0.2322, 0.2886,  ..., 0.0423, 0.0201, 0.0382]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0679, 0.0191, 0.0098,  ..., 0.0540, 0.2024, 0.2600],\n",
       "          [0.0719, 0.2008, 0.0298,  ..., 0.0463, 0.1936, 0.1338],\n",
       "          [0.0351, 0.4597, 0.2250,  ..., 0.0399, 0.0266, 0.0398],\n",
       "          ...,\n",
       "          [0.0200, 0.0746, 0.0812,  ..., 0.0386, 0.1539, 0.0293],\n",
       "          [0.1305, 0.0409, 0.0435,  ..., 0.3115, 0.0709, 0.1144],\n",
       "          [0.0131, 0.1197, 0.0388,  ..., 0.4499, 0.1321, 0.0381]],\n",
       " \n",
       "         [[0.1498, 0.1994, 0.1272,  ..., 0.0276, 0.0543, 0.2313],\n",
       "          [0.0095, 0.1064, 0.0577,  ..., 0.1378, 0.1133, 0.1291],\n",
       "          [0.0306, 0.0709, 0.1020,  ..., 0.0296, 0.0132, 0.0997],\n",
       "          ...,\n",
       "          [0.1048, 0.1113, 0.1438,  ..., 0.0294, 0.0113, 0.1892],\n",
       "          [0.0390, 0.0831, 0.5550,  ..., 0.0547, 0.0164, 0.0083],\n",
       "          [0.0823, 0.0560, 0.2449,  ..., 0.1485, 0.0392, 0.0373]],\n",
       " \n",
       "         [[0.1612, 0.0515, 0.4353,  ..., 0.0433, 0.0820, 0.0582],\n",
       "          [0.0567, 0.3108, 0.0956,  ..., 0.0808, 0.0403, 0.0445],\n",
       "          [0.0127, 0.3185, 0.0269,  ..., 0.1816, 0.1472, 0.0411],\n",
       "          ...,\n",
       "          [0.0607, 0.1546, 0.0083,  ..., 0.1444, 0.2443, 0.0220],\n",
       "          [0.0528, 0.0188, 0.0205,  ..., 0.0470, 0.0859, 0.0566],\n",
       "          [0.0716, 0.0293, 0.0511,  ..., 0.1635, 0.0219, 0.2198]]],\n",
       "        grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

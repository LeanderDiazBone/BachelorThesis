{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import scvi\n",
    "from scib_metrics.benchmark import Benchmarker\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from functions import *\n",
    "import scib_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\n",
    "    \"data/Immune_ALL_hum_mou.h5ad\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 genes among all datasets\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.73170003e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.03016241e-01\n",
      "  4.59418070e-03 2.33243968e-02 7.18840580e-02 2.58658483e-02\n",
      "  1.37328340e-02 1.36363636e-02 1.32093933e-01]\n",
      " [0.00000000e+00 0.00000000e+00 5.50835566e-01 5.12820513e-02\n",
      "  2.61512948e-02 0.00000000e+00 7.56715853e-04 1.27567292e-04\n",
      "  0.00000000e+00 6.36942675e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.71040127e-01\n",
      "  6.18152524e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.86090226e-01 0.00000000e+00 3.97275823e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.09358082e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.90655209e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.11060189e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.32018561e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.97550045e-04 0.00000000e+00\n",
      "  0.00000000e+00 9.55414013e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.40845070e-03 2.20417633e-02\n",
      "  5.51301685e-03 3.31640275e-02 6.59130435e-01 2.77948268e-01\n",
      "  3.00873908e-01 2.30578512e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.83617102e-01\n",
      "  1.95043511e-01 1.68789809e-01 1.47091515e-01 5.25511763e-02\n",
      "  6.63265306e-02 3.75426621e-02 1.40845070e-02 5.02706883e-03\n",
      "  0.00000000e+00 0.00000000e+00 5.79710145e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.37628613e-01 1.27388535e-02 7.68803260e-01 1.09990834e-02\n",
      "  3.06122449e-02 1.36518771e-02 5.63380282e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.18471338e-03 4.63875509e-01 0.00000000e+00\n",
      "  5.10204082e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.91082803e-02 9.68152866e-01\n",
      "  8.16326531e-02 1.60409556e-01 6.56050955e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.38940348e-01\n",
      "  1.37755102e-01 8.87372014e-02 4.78873239e-02 2.96406076e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.18367347e-01 9.18088737e-01 9.60563380e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.02047782e-01 3.46938776e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.08532423e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.43310131e-01 8.89404486e-01 6.95652174e-03 3.09358082e-03\n",
      "  5.28506034e-02 2.04949729e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.37519142e-01 7.35068913e-03 3.94563788e-03\n",
      "  7.49063670e-03 2.45022971e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.31884058e-02 2.49890399e-02\n",
      "  2.39678284e-01 5.68364611e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.55652174e-01\n",
      "  3.54202899e-01 3.13043478e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.23849189e-01 4.24375274e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.84727424e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Processing datasets (9, 11)\n",
      "Processing datasets (11, 14)\n",
      "Processing datasets (11, 12)\n",
      "Processing datasets (11, 13)\n",
      "Processing datasets (15, 17)\n",
      "Processing datasets (20, 21)\n",
      "Processing datasets (2, 3)\n",
      "Processing datasets (18, 19)\n",
      "Processing datasets (12, 13)\n",
      "Processing datasets (7, 10)\n",
      "Processing datasets (7, 8)\n",
      "Processing datasets (3, 4)\n",
      "Processing datasets (5, 18)\n",
      "Processing datasets (9, 14)\n",
      "Processing datasets (19, 20)\n",
      "Processing datasets (2, 4)\n",
      "Processing datasets (6, 7)\n",
      "Processing datasets (1, 2)\n",
      "Processing datasets (15, 16)\n",
      "Processing datasets (16, 17)\n",
      "Processing datasets (13, 14)\n",
      "Processing datasets (8, 10)\n",
      "Processing datasets (19, 21)\n",
      "Processing datasets (0, 5)\n",
      "Processing datasets (18, 20)\n",
      "Processing datasets (12, 14)\n",
      "Processing datasets (18, 21)\n",
      "Processing datasets (5, 20)\n",
      "Processing datasets (5, 19)\n",
      "Processing datasets (17, 20)\n",
      "Processing datasets (5, 21)\n",
      "Processing datasets (0, 15)\n",
      "Processing datasets (6, 8)\n",
      "Processing datasets (6, 9)\n",
      "Processing datasets (9, 13)\n",
      "Processing datasets (6, 10)\n",
      "Processing datasets (10, 11)\n",
      "Processing datasets (10, 12)\n",
      "Processing datasets (0, 22)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(adata, n_top_genes=4000, flavor=\"cell_ranger\", batch_key=\"batch\")\n",
    "sc.tl.pca(adata, n_comps=30, use_highly_variable=True)\n",
    "adata = adata[:, adata.var.highly_variable].copy()\n",
    "adata.obsm[\"Unintegrated\"] = adata.obsm[\"X_pca\"]\n",
    "scanoramaPredict(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(filename=\"data/adataMou4.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 97861 × 4000\n",
       "    obs: 'batch', 'chemistry', 'data_type', 'dpt_pseudotime', 'final_annotation', 'mt_frac', 'n_counts', 'n_genes', 'size_factors', 'species', 'study', 'tissue'\n",
       "    var: 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n",
       "    uns: 'hvg', 'pca'\n",
       "    obsm: 'Scanorama', 'Unintegrated', 'X_pca'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = anndata.read_h5ad(filename=\"data/adataMou4.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/sd200epMouBench\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [19:41<00:00,  5.59s/it, v_num=0, train_loss_step=1.27e+3, train_loss_epoch=1.64e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [19:41<00:00,  5.91s/it, v_num=0, train_loss_step=1.27e+3, train_loss_epoch=1.64e+3]\n"
     ]
    }
   ],
   "source": [
    "sdnormalAdata, vaeSD = trainModelBenchmark(adata.copy(), \"sdnormal\", max_epochs=200,log=True, logname=\"sd200epMouBench\",early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/mog200epMouBench\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [23:14<00:00,  6.40s/it, v_num=0, train_loss_step=1.61e+3, train_loss_epoch=1.64e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [23:14<00:00,  6.97s/it, v_num=0, train_loss_step=1.61e+3, train_loss_epoch=1.64e+3]\n"
     ]
    }
   ],
   "source": [
    "mogAdata, vaeMG = trainModelBenchmark(adata.copy(), \"mixofgaus\", max_epochs=200,log=True, logname=\"mog200epMouBench\",early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/vampsd200epMouBench\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200:  97%|█████████▋| 194/200 [23:02<00:42,  7.13s/it, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=1.64e+3]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 1654.485. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "vampAdata, vaeVP = trainModelBenchmark(adata.copy(), \"vamp\", max_epochs = 200,log=True,logname=\"vampsd200epMouBench\",early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/flow100epMouBench\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [52:53<00:00, 28.00s/it, v_num=0, train_loss_step=1.52e+3, train_loss_epoch=1.64e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [52:54<00:00, 31.74s/it, v_num=0, train_loss_step=1.52e+3, train_loss_epoch=1.64e+3]\n"
     ]
    }
   ],
   "source": [
    "flowAdata, vaeNF = trainModelBenchmark(adata.copy(), 'normalflow', max_epochs=100, log=True, logname=\"flow100epMouBench\",early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAdata = sdnormalAdata.copy()\n",
    "allAdata.obsm[\"scVISD\"] = sdnormalAdata.obsm[\"scVI\"]\n",
    "allAdata.obsm[\"scVIMG\"] = mogAdata.obsm[\"scVI\"]\n",
    "allAdata.obsm[\"scVIVAMP\"] = vampAdata.obsm[\"scVI\"]\n",
    "allAdata.obsm[\"scVINF\"] = flowAdata.obsm[\"scVI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 6/6 [09:16<00:00, 92.68s/it] \n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/6 [00:00<?, ?it/s]INFO:root:isolated labels: no more than 1 batches per label\n",
      "INFO:root:T cells: 0.39853960275650024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m T cells consists of a single batch or is too small. Skip.                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings:  17%|\u001b[32m█▋        \u001b[0m| 1/6 [02:20<11:42, 140.50s/it]INFO:root:isolated labels: no more than 1 batches per label\n",
      "INFO:root:T cells: 0.49366109212860465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m T cells consists of a single batch or is too small. Skip.                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings:  33%|\u001b[32m███▎      \u001b[0m| 2/6 [24:29<55:57, 839.48s/it]INFO:root:isolated labels: no more than 1 batches per label\n",
      "INFO:root:T cells: 0.4258524030447006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m T cells consists of a single batch or is too small. Skip.                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings:  50%|\u001b[32m█████     \u001b[0m| 3/6 [26:36<25:42, 514.06s/it]INFO:root:isolated labels: no more than 1 batches per label\n",
      "INFO:root:T cells: 0.38777443021535873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m T cells consists of a single batch or is too small. Skip.                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings:  67%|\u001b[32m██████▋   \u001b[0m| 4/6 [28:43<12:02, 361.49s/it]INFO:root:isolated labels: no more than 1 batches per label\n",
      "INFO:root:T cells: 0.3756677806377411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m T cells consists of a single batch or is too small. Skip.                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings:  83%|\u001b[32m████████▎ \u001b[0m| 5/6 [30:48<04:36, 276.20s/it]INFO:root:isolated labels: no more than 1 batches per label\n",
      "INFO:root:T cells: 0.4039226770401001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m T cells consists of a single batch or is too small. Skip.                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 6/6 [32:54<00:00, 329.09s/it]\n"
     ]
    }
   ],
   "source": [
    "plotBenchmarkResults(allAdata,keys = [\"Unintegrated\",\"Scanorama\",\"scVISD\",\"scVIMG\",\"scVIVAMP\",\"scVINF\"],label_key=\"final_annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1342), started 1:50:59 ago. (Use '!kill 1342' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f777413ae50>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([1],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
